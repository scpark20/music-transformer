{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import ntpath\n",
    "\n",
    "data_dir = 'dataset_cc/'\n",
    "\n",
    "data_files = []\n",
    "\n",
    "data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if '.npz' in f]\n",
    "print(len(data_files))\n",
    "\n",
    "data_files.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Interval\n",
    "'''\n",
    "# Divide 1second by 200 equally\n",
    "IntervalDim = 200\n",
    "\n",
    "'''\n",
    "Velocity\n",
    "'''\n",
    "# Divide Midi velocity values[0, 127] by 32\n",
    "VelocityDim = 32\n",
    "VelocityOffset = IntervalDim\n",
    "\n",
    "'''\n",
    "Note On/Off\n",
    "'''\n",
    "# Note values [0, 127]\n",
    "NoteOnDim = NoteOffDim = 128\n",
    "NoteOnOffset = IntervalDim + VelocityDim\n",
    "NoteOffOffset = IntervalDim + VelocityDim + NoteOnDim\n",
    "\n",
    "'''\n",
    "CC On/Off\n",
    "'''\n",
    "# CC = sustain pedal on/off\n",
    "CCDim = 2\n",
    "CCOffset = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim\n",
    "\n",
    "'''\n",
    "Total Event Dim\n",
    "'''\n",
    "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim + CCDim # 390\n",
    "\n",
    "'''\n",
    "Other Hyperparameters\n",
    "'''\n",
    "# Attention Range\n",
    "Time = 2000\n",
    "# Event Embedding Dimension\n",
    "EmbeddingDim = 512 \n",
    "\n",
    "# Multi-head Attention Related\n",
    "HeadDim = 32 \n",
    "Heads = 16\n",
    "ContextDim = HeadDim * Heads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from npz and converter to token sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape :  (2000,)\n",
      "y shape :  (2000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "def get_data(length=Time):\n",
    "    # load data randomly\n",
    "    index = np.random.randint(0, len(data_files))\n",
    "    data = np.load(data_files[index])['eventlist']\n",
    "    \n",
    "    # time augmentation\n",
    "    data[:, 0] *= np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # absolute time to relative interval\n",
    "    data[1:, 0] = data[1:, 0] - data[:-1, 0]\n",
    "    data[0, 0] = 0\n",
    "    \n",
    "    # discretize interval into IntervalDim\n",
    "    data[:, 0] = np.clip(np.round(data[:, 0] * IntervalDim), 0, IntervalDim - 1)\n",
    "    \n",
    "    # Note augmentation\n",
    "    data[:, 2] += np.random.randint(-6, 6)\n",
    "    data[:, 2] = np.clip(data[:, 2], 0, NoteOnDim)\n",
    "    \n",
    "    eventlist = []\n",
    "    for d in data:\n",
    "        # append interval\n",
    "        interval = d[0]\n",
    "        eventlist.append(interval)\n",
    "    \n",
    "        # note on case\n",
    "        if d[1] == 1:\n",
    "            velocity = (d[3] / 128) * VelocityDim + VelocityOffset\n",
    "            note = d[2] + NoteOnOffset\n",
    "            eventlist.append(velocity)\n",
    "            eventlist.append(note)\n",
    "            \n",
    "        # note off case\n",
    "        elif d[1] == 0:\n",
    "            note = d[2] + NoteOffOffset\n",
    "            eventlist.append(note)\n",
    "        # CC\n",
    "        elif d[1] == 2:\n",
    "            event = CCOffset + d[3]\n",
    "            eventlist.append(event)\n",
    "            \n",
    "    eventlist = np.array(eventlist).astype(np.int)\n",
    "    \n",
    "    if len(eventlist) > (length+1):\n",
    "        start_index = np.random.randint(0, len(eventlist) - (length+1))\n",
    "        eventlist = eventlist[start_index:start_index+(length+1)]\n",
    "        \n",
    "    # pad zeros\n",
    "    if len(eventlist) < (length+1):\n",
    "        pad = (length+1) - len(eventlist)\n",
    "        eventlist = np.pad(eventlist, (pad, 0), 'constant')\n",
    "        \n",
    "    x = eventlist[:length]\n",
    "    y = eventlist[1:length+1]\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "x, y = get_data()\n",
    "print('x shape : ', x.shape)\n",
    "print('y shape : ', y.shape)\n",
    "# print(x)\n",
    "# print(y)\n",
    "    \n",
    "'''\n",
    "Visualization\n",
    "'''\n",
    "roll = np.zeros([len(x), EventDim])\n",
    "for t, _x in enumerate(x):\n",
    "    roll[t, _x] = 1\n",
    "\n",
    "plt.figure(figsize=[18, 15])\n",
    "librosa.display.specshow(roll.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 Source referenced from https://github.com/openai/gpt-2/blob/master/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.training import HParams\n",
    "\n",
    "def default_hparams():\n",
    "    return HParams(\n",
    "        n_vocab=EventDim,\n",
    "        n_ctx=1024,\n",
    "        n_embd=768,\n",
    "        n_head=12,\n",
    "        n_layer=6,\n",
    "        n_time=Time,\n",
    "    )\n",
    "\n",
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x = x - tf.reduce_max(x, axis=axis, keepdims=True)\n",
    "    ex = tf.exp(x)\n",
    "    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
    "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        n_state = x.shape[-1].value\n",
    "        g = tf.get_variable('g', [n_state], initializer=tf.constant_initializer(1))\n",
    "        b = tf.get_variable('b', [n_state], initializer=tf.constant_initializer(0))\n",
    "        u = tf.reduce_mean(x, axis=axis, keepdims=True)\n",
    "        s = tf.reduce_mean(tf.square(x-u), axis=axis, keepdims=True)\n",
    "        x = (x - u) * tf.rsqrt(s + epsilon)\n",
    "        x = x*g + b\n",
    "        return x\n",
    "\n",
    "def split_states(x, n):\n",
    "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
    "    *start, m = shape_list(x)\n",
    "    return tf.reshape(x, start + [n, m//n])\n",
    "\n",
    "def merge_states(x):\n",
    "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
    "    *start, a, b = shape_list(x)\n",
    "    return tf.reshape(x, start + [a*b])\n",
    "\n",
    "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
    "    with tf.variable_scope(scope):\n",
    "        *start, nx = shape_list(x)\n",
    "        w = tf.get_variable('w', [1, nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))\n",
    "        b = tf.get_variable('b', [nf], initializer=tf.constant_initializer(0))\n",
    "        c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n",
    "        return c\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "\n",
    "def attn(x, scope, n_state, *, hparams):\n",
    "    assert x.shape.ndims == 3  # Should be [batch, sequence, features]\n",
    "    assert n_state % hparams.n_head == 0\n",
    "\n",
    "    def split_heads(x):\n",
    "        # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
    "        return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
    "\n",
    "    def merge_heads(x):\n",
    "        # Reverse of split_heads\n",
    "        return merge_states(tf.transpose(x, [0, 2, 1, 3]))\n",
    "\n",
    "    def mask_attn_weights(w):\n",
    "        # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "        _, _, nd, ns = shape_list(w)\n",
    "        b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "        b = tf.reshape(b, [1, 1, nd, ns])\n",
    "        w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "        return w\n",
    "    \n",
    "    def relative_attn(q):\n",
    "        # q have shape [batch, heads, sequence, features]\n",
    "        batch, heads, sequence, features = shape_list(q)\n",
    "        E = tf.get_variable('E', [heads, sequence, features])\n",
    "        # [heads, batch, sequence, features]\n",
    "        q_ = tf.transpose(q, [1, 0, 2, 3])\n",
    "        # [heads, batch * sequence, features]\n",
    "        q_ = tf.reshape(q_, [heads, batch * sequence, features])\n",
    "        # [heads, batch * sequence, sequence]\n",
    "        rel = tf.matmul(q_, E, transpose_b=True)\n",
    "        # [heads, batch, sequence, sequence]\n",
    "        rel = tf.reshape(rel, [heads, batch, sequence, sequence])\n",
    "        # [heads, batch, sequence, 1+sequence]\n",
    "        rel = tf.pad(rel, ((0, 0), (0, 0), (0, 0), (1, 0)))\n",
    "        # [heads, batch, sequence+1, sequence]\n",
    "        rel = tf.reshape(rel, (heads, batch, sequence+1, sequence))\n",
    "        # [heads, batch, sequence, sequence]\n",
    "        rel = rel[:, :, 1:]\n",
    "        # [batch, heads, sequence, sequence]\n",
    "        rel = tf.transpose(rel, [1, 0, 2, 3])\n",
    "        return rel\n",
    "        \n",
    "    def multihead_attn(q, k, v):\n",
    "        # q, k, v have shape [batch, heads, sequence, features]\n",
    "        w = tf.matmul(q, k, transpose_b=True)\n",
    "        w = w + relative_attn(q)\n",
    "        w = w * tf.rsqrt(tf.cast(v.shape[-1].value, w.dtype))\n",
    "\n",
    "        w = mask_attn_weights(w)\n",
    "        w = softmax(w)\n",
    "        a = tf.matmul(w, v)\n",
    "        return a\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        c = conv1d(x, 'c_attn', n_state*3)\n",
    "        q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
    "        present = tf.stack([k, v], axis=1)\n",
    "\n",
    "        a = multihead_attn(q, k, v)\n",
    "        a = merge_heads(a)\n",
    "        a = conv1d(a, 'c_proj', n_state)\n",
    "        return a, present\n",
    "\n",
    "\n",
    "def mlp(x, scope, n_state, *, hparams):\n",
    "    with tf.variable_scope(scope):\n",
    "        nx = x.shape[-1].value\n",
    "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
    "        h2 = conv1d(h, 'c_proj', nx)\n",
    "        return h2\n",
    "\n",
    "\n",
    "def block(x, scope, *, hparams):\n",
    "    with tf.variable_scope(scope):\n",
    "        nx = x.shape[-1].value\n",
    "        a, present = attn(norm(x, 'ln_1'), 'attn', nx, hparams=hparams)\n",
    "        x = x + a\n",
    "        m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
    "        x = x + m\n",
    "        return x, present\n",
    "\n",
    "def expand_tile(value, size):\n",
    "    \"\"\"Add a new axis of given size.\"\"\"\n",
    "    value = tf.convert_to_tensor(value, name='value')\n",
    "    ndims = value.shape.ndims\n",
    "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
    "\n",
    "def model(hparams, X, scope='model', reuse=False):\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        results = {}\n",
    "        batch, sequence = shape_list(X)\n",
    "\n",
    "        wte = tf.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
    "                             initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        h = tf.gather(wte, X)\n",
    "\n",
    "        # Transformer\n",
    "        presents = []\n",
    "        for layer in range(hparams.n_layer):\n",
    "            h, present = block(h, 'h%d' % layer, hparams=hparams)\n",
    "            presents.append(present)\n",
    "        results['present'] = tf.stack(presents, axis=1)\n",
    "        h = norm(h, 'ln_f')\n",
    "\n",
    "        # Language model loss.  Do tokens <n predict token n?\n",
    "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
    "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
    "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
    "        results['logits'] = logits\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Graph Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n_ctx', 1024), ('n_embd', 768), ('n_head', 12), ('n_layer', 6), ('n_time', 2000), ('n_vocab', 490)]\n",
      "graph create\n"
     ]
    }
   ],
   "source": [
    "hparams = default_hparams()\n",
    "print(hparams)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
    "Y = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
    "\n",
    "X_onehot = tf.one_hot(X, axis=2, depth=hparams.n_vocab)\n",
    "\n",
    "logits = model(hparams, X)['logits']\n",
    "probs = tf.nn.softmax(logits, axis=2)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#temperature = tf.Variable(1., name='temperature')\n",
    "temperature = 0\n",
    "u = tf.random.uniform(shape=tf.shape(logits[:, -1]), minval=1e-5, maxval=1.-1e-5)\n",
    "u = (logits[:, -1] - tf.log(temperature + 1e-8)) - tf.log(-tf.log(u))\n",
    "sample = tf.argmax(u, axis=1)\n",
    "\n",
    "#dist = tf.distributions.Categorical(logits=logits[:, -1])\n",
    "#sample = dist.sample()\n",
    "\n",
    "'''\n",
    "Train\n",
    "'''\n",
    "global_step = tf.Variable(0, name='global_step')\n",
    "learning_rate = tf.Variable(1e-3, name='learning_rate')\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "\n",
    "'''\n",
    "Session Open\n",
    "'''\n",
    "\n",
    "sess_config = tf.ConfigProto()\n",
    "# GPU number to use\n",
    "\n",
    "gpu_options = tf.GPUOptions(visible_device_list= '1')\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('graph create')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model if exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "load_dir = 'save/gpt2-cc-interval200-attention1000'\n",
    "save_dir = 'save/gpt2-cc-interval200-attention1000'\n",
    "\n",
    "def get_variables_from_checkpoint_file(file_name):\n",
    "    variables = []\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
    "\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "    for key in sorted(var_to_shape_map):\n",
    "        variables.append((key, var_to_shape_map[key]))\n",
    "\n",
    "    return variables\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# set True to load model\n",
    "if False:\n",
    "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
    "    if restore_file is not None:\n",
    "        try:\n",
    "            saver.restore(sess, restore_file)\n",
    "            print(\"Model restored.\")\n",
    "            \n",
    "        # Partial weight load\n",
    "        except: \n",
    "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
    "            model_variables = slim.get_variables_to_restore()\n",
    "            restore_variables = []\n",
    "            for model_variable in model_variables:\n",
    "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
    "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
    "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
    "                        restore_variables.append(model_variable)\n",
    "\n",
    "            init_saver = tf.train.Saver(restore_variables)\n",
    "            init_saver.restore(sess, restore_file)\n",
    "            print(\"Model partially restored.\")\n",
    "    else:\n",
    "        print('model not exist.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "class Logger(SummaryWriter):\n",
    "    def __init__(self, logdir):\n",
    "        super(Logger, self).__init__(logdir)\n",
    "\n",
    "    def log(self, log_string, value, iteration):\n",
    "            self.add_scalar(log_string, value, iteration)\n",
    "            \n",
    "logger = Logger(save_dir)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2000) (1, 2000)\n",
      "1 6.418178\n",
      "(1, 2000) (1, 2000)\n",
      "2 5.5366173\n",
      "(1, 2000) (1, 2000)\n",
      "3 5.2478614\n",
      "(1, 2000) (1, 2000)\n",
      "4 4.843927\n",
      "(1, 2000) (1, 2000)\n",
      "5 5.147655\n",
      "(1, 2000) (1, 2000)\n",
      "6 5.7431297\n",
      "(1, 2000) (1, 2000)\n",
      "7 5.150187\n",
      "(1, 2000) (1, 2000)\n",
      "8 5.085401\n",
      "(1, 2000) (1, 2000)\n",
      "9 5.3632436\n",
      "(1, 2000) (1, 2000)\n",
      "10 4.5786376\n",
      "(1, 2000) (1, 2000)\n",
      "11 4.9180484\n",
      "(1, 2000) (1, 2000)\n",
      "12 5.3092713\n",
      "(1, 2000) (1, 2000)\n",
      "13 4.7769356\n",
      "(1, 2000) (1, 2000)\n",
      "14 5.44524\n",
      "(1, 2000) (1, 2000)\n",
      "15 5.563039\n",
      "(1, 2000) (1, 2000)\n",
      "16 4.3149414\n",
      "(1, 2000) (1, 2000)\n",
      "17 5.0529504\n",
      "(1, 2000) (1, 2000)\n",
      "18 5.049242\n",
      "(1, 2000) (1, 2000)\n",
      "19 5.1288996\n",
      "(1, 2000) (1, 2000)\n",
      "20 5.577233\n",
      "(1, 2000) (1, 2000)\n",
      "21 5.27534\n",
      "(1, 2000) (1, 2000)\n",
      "22 5.003042\n",
      "(1, 2000) (1, 2000)\n",
      "23 4.869605\n",
      "(1, 2000) (1, 2000)\n",
      "24 4.943798\n",
      "(1, 2000) (1, 2000)\n",
      "25 4.92558\n",
      "(1, 2000) (1, 2000)\n",
      "26 4.8403006\n",
      "(1, 2000) (1, 2000)\n",
      "27 4.7397447\n",
      "(1, 2000) (1, 2000)\n",
      "28 5.3120713\n",
      "(1, 2000) (1, 2000)\n",
      "29 4.7124524\n",
      "(1, 2000) (1, 2000)\n",
      "30 4.7584023\n",
      "(1, 2000) (1, 2000)\n",
      "31 4.9257374\n",
      "(1, 2000) (1, 2000)\n",
      "32 4.6476994\n",
      "(1, 2000) (1, 2000)\n",
      "33 4.6749787\n",
      "(1, 2000) (1, 2000)\n",
      "34 4.7355013\n",
      "(1, 2000) (1, 2000)\n",
      "35 4.845387\n",
      "(1, 2000) (1, 2000)\n",
      "36 4.9596076\n",
      "(1, 2000) (1, 2000)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-57fa4e2bcd5b>\", line 30, in <module>\n",
      "    learning_rate: 1e-3})\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/scpark/anaconda3/envs/ai/lib/python3.6/posixpath.py\", line 170, in islink\n",
      "    try:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from time import sleep\n",
    "import time\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "while(True):\n",
    "    #sleep(5)\n",
    "    for _ in range(100):\n",
    "        _inputs = []\n",
    "        _targets = []\n",
    "        for _ in range(batch_size):\n",
    "            while(True):\n",
    "                x, y = get_data(hparams.n_time)\n",
    "                if(x.shape == y.shape):\n",
    "                    break\n",
    "                 \n",
    "            _inputs.append(x)\n",
    "            _targets.append(y)\n",
    "        _inputs = np.stack(_inputs)\n",
    "        _targets = np.stack(_targets)\n",
    "        print(_inputs.shape, _targets.shape)\n",
    "        \n",
    "        _, _global_step, _loss = sess.run([train_step, global_step, loss], \n",
    "                                          feed_dict={X: _inputs, \n",
    "                                                     Y: _targets,\n",
    "                                                     learning_rate: 1e-3})\n",
    "        print(_global_step, _loss)\n",
    "        \n",
    "        if _global_step % 10 == 0:\n",
    "            logger.log('loss', _loss, _global_step)\n",
    "        \n",
    "        if _global_step % 1000 == 0:\n",
    "            save_path = saver.save(sess, save_dir + '/checkpoint', global_step=_global_step)\n",
    "            print(\"Model saved in path: %s\" % save_path)\n",
    "        \n",
    "    clear_output()\n",
    "    \n",
    "    _inputs_onehot, _probs = sess.run([X_onehot, probs], feed_dict={X: _inputs})\n",
    "    \n",
    "    plt.figure(figsize=[18, 8])\n",
    "    librosa.display.specshow(_inputs_onehot[0].T)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=[18, 8])\n",
    "    librosa.display.specshow(_probs[0].T)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "for sequence in range(0, 10):\n",
    "\n",
    "    # Length to inference\n",
    "    N = 4000\n",
    "\n",
    "    x, y = get_data(hparams.n_time)\n",
    "    _inputs = np.zeros([1, N], dtype=np.int32)\n",
    "    _inputs[:, :len(x)] = x[None, :]\n",
    "    print(_inputs)\n",
    "\n",
    "    for i in tqdm(range(N-Time)):\n",
    "\n",
    "        _sample, _prob = sess.run([sample, probs], feed_dict={X: _inputs[:, i:i+Time]})\n",
    "        _inputs[:, i+Time] = _sample \n",
    "\n",
    "    print(_inputs.shape)\n",
    "\n",
    "    class Event():\n",
    "        def __init__(self, time, note, cc, on, velocity):\n",
    "            self.time = time\n",
    "            self.note = note\n",
    "            self.on = on\n",
    "            self.cc = cc\n",
    "            self.velocity = velocity\n",
    "\n",
    "        def get_event_sequence(self):\n",
    "            return [self.time, self.note, int(self.on)]\n",
    "\n",
    "    class Note():\n",
    "        def __init__(self):\n",
    "            self.pitch = 0\n",
    "            self.start_time = 0\n",
    "            self.end_time = 0\n",
    "\n",
    "    event_list = []\n",
    "    time = 0\n",
    "    event = None\n",
    "\n",
    "    EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim # 388\n",
    "\n",
    "    for _input in _inputs[0]:\n",
    "        # interval\n",
    "        if _input < IntervalDim: \n",
    "            time += _input\n",
    "            event = Event(time, 0, False, 0, 0)\n",
    "\n",
    "        # velocity\n",
    "        elif _input < NoteOnOffset:\n",
    "            if event is None:\n",
    "                continue\n",
    "            event.velocity = (_input - VelocityOffset) / VelocityDim * 128\n",
    "            #print('velocity : ', event.velocity)\n",
    "\n",
    "        # note on\n",
    "        elif _input < NoteOffOffset:\n",
    "            if event is None:\n",
    "                continue\n",
    "\n",
    "            event.note = _input - NoteOnOffset\n",
    "            event.on = True\n",
    "            event_list.append(event)\n",
    "            #event_list.append(Event(event.time + 100, event.note, False))\n",
    "            event = None\n",
    "\n",
    "        # note off\n",
    "        elif _input < CCOffset:\n",
    "            if event is None:\n",
    "                continue\n",
    "            event.note = _input - NoteOffOffset\n",
    "            event.on = False\n",
    "            event_list.append(event)\n",
    "            event = None\n",
    "\n",
    "        ## CC\n",
    "        else:\n",
    "            if event is None:\n",
    "                continue\n",
    "            event.cc = True\n",
    "            on = _input - CCOffset == 1\n",
    "            event.on = on\n",
    "            #print(on)\n",
    "            event_list.append(event)\n",
    "            event = None\n",
    "\n",
    "    import midi\n",
    "    # Instantiate a MIDI Pattern (contains a list of tracks)\n",
    "    pattern = midi.Pattern()\n",
    "    # Instantiate a MIDI Track (contains a list of MIDI events)\n",
    "    track = midi.Track()\n",
    "    # Append the track to the pattern\n",
    "    pattern.append(track)\n",
    "\n",
    "    prev_time = 0\n",
    "    pitches = [None for _ in range(128)]\n",
    "    for event in event_list:\n",
    "        tick = (event.time - prev_time) * 5\n",
    "        prev_time = event.time\n",
    "\n",
    "        # case NOTE:\n",
    "        if not event.cc:\n",
    "            if event.on:\n",
    "                if pitches[event.note] is not None:\n",
    "                    # Instantiate a MIDI note off event, append it to the track\n",
    "                    off = midi.NoteOffEvent(tick=0, pitch=event.note)\n",
    "                    track.append(off)\n",
    "                    pitches[event.note] = None\n",
    "\n",
    "                # Instantiate a MIDI note on event, append it to the track\n",
    "                on = midi.NoteOnEvent(tick=tick, velocity=int(event.velocity), pitch=event.note)\n",
    "                track.append(on)\n",
    "                pitches[event.note] = prev_time\n",
    "            else:\n",
    "                # Instantiate a MIDI note off event, append it to the track\n",
    "                off = midi.NoteOffEvent(tick=tick, pitch=event.note)\n",
    "                track.append(off)\n",
    "                pitches[event.note] = None\n",
    "\n",
    "        # case CC:\n",
    "        elif event.cc:\n",
    "            if event.on:\n",
    "                cc = midi.ControlChangeEvent(tick=tick, control=64, value=64)\n",
    "            else:\n",
    "                cc = midi.ControlChangeEvent(tick=tick, control=64, value=0)\n",
    "\n",
    "            track.append(cc)\n",
    "\n",
    "        for pitch in range(128):\n",
    "            if pitches[pitch] is not None and pitches[pitch] + 100 < prev_time:\n",
    "                #print('here')\n",
    "                off = midi.NoteOffEvent(tick=0, pitch=pitch)\n",
    "                track.append(off)\n",
    "                pitches[pitch] = None\n",
    "\n",
    "\n",
    "    # Add the end of track event, append it to the track\n",
    "    eot = midi.EndOfTrackEvent(tick=1)\n",
    "    track.append(eot)\n",
    "    # Print out the pattern\n",
    "    #print(pattern)\n",
    "    # Save the pattern to disk\n",
    "    midi.write_midifile(\"example_-\" + str(sequence) + \".mid\", pattern)\n",
    "\n",
    "    print('done')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
